{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d3c921-082a-4fc0-99b4-4c357981d1d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing of Compound Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5dffe-4217-45fd-baae-a2c732ca0d56",
   "metadata": {},
   "source": [
    "## 0. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaa9ae-40c9-48e1-afdb-488b7a43b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements \n",
    "#!pip3 install german-nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80ce22d-4fac-42a4-900e-3f823c8c6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "from german_nouns.lookup import Nouns\n",
    "nouns = Nouns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205aa9f-e00d-44fd-818a-3bbcef67b4f8",
   "metadata": {},
   "source": [
    "## 1. Load Input\n",
    "\n",
    "In this step we load the list of glossary terms and split the compounds into its two components, i.e. \"Klima\" and \"X\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d6109f-9b8b-4af2-8c64-6a8ba501e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wordlist as list of strings \n",
    "with open('../files/wordlist.txt') as f:\n",
    "    wordlist = f.read().splitlines()\n",
    "\n",
    "# get second part (noun) of climate compounds and save to new list\n",
    "second_nouns = []\n",
    "for noun in wordlist:\n",
    "    second_nouns.append(noun.split(\"Klima\",1)[1])\n",
    "\n",
    "# create dictionary from wordlist and second part of compounds\n",
    "d = {\"original\":wordlist,\"second_part\":second_nouns}\n",
    "\n",
    "# create dataframe containing both information, \n",
    "# the original compounds and the second part of the compounds \n",
    "compounds = pd.DataFrame(d, columns = [\"original\", \"second_part\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc2808-34e9-44c5-a572-f7d7703dd84e",
   "metadata": {},
   "source": [
    "## 2. Preprocessing \n",
    "\n",
    "In the following code, we create functions to be able to easily retrieve the declension forms of the noun, the lemma forms and the genus for each compound word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b36436-3f2f-4888-8933-bc4a02495cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions retrieve word forms, lemmas and genus from german-nouns library \n",
    "# for the second noun part of our climate change compound nouns \n",
    "\n",
    "def get_forms(word):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function retrieves the word forms of the second part of each compound word. \n",
    "    Arg: \n",
    "        df: The word we want to retrieve the word forms (declension forms) for. \n",
    "    Returns: The noun forms for each noun if available, else None.   \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        noun_forms = list(set(nouns[word][0][\"flexion\"].values())) # get all noun forms as a list\n",
    "        return noun_forms      \n",
    "    except:  \n",
    "        return \n",
    "    \n",
    "def get_lemma(word):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function retrieves the lemma forms of the second part of each compound word. \n",
    "    Arg: \n",
    "        df: The word for which we want to retrieve the lemma form. \n",
    "    Returns: The lemma form for each noun if available, else None.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        lemma = nouns[word][0][\"lemma\"] # retrieve lemma form\n",
    "        return lemma  \n",
    "    except:\n",
    "        return \n",
    "    \n",
    "def get_genus(word):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function retrieves the genus of the second part of each compound word. \n",
    "    Arg: \n",
    "        df: The word for which we want to retrieve the genus. \n",
    "    Returns: The genus for each noun if available, else None.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        genus = nouns[word][0][\"genus\"] # retrieve genus\n",
    "        return genus\n",
    "    except:\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c84bf1-7220-4d28-97e9-cfb0aaa31ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>second_part</th>\n",
       "      <th>noun_forms</th>\n",
       "      <th>lemma</th>\n",
       "      <th>genus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Klimaabzockerei</td>\n",
       "      <td>abzockerei</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Klimaaktivismus</td>\n",
       "      <td>aktivismus</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Klimaaktivist</td>\n",
       "      <td>aktivist</td>\n",
       "      <td>[Aktivisten, Aktivist]</td>\n",
       "      <td>Aktivist</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Klimaaktivistin</td>\n",
       "      <td>aktivistin</td>\n",
       "      <td>[Aktivistinnen, Aktivistin]</td>\n",
       "      <td>Aktivistin</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Klimaalarm</td>\n",
       "      <td>alarm</td>\n",
       "      <td>[Alarms, Alarm, Alarmen, Alarme, Alarmes]</td>\n",
       "      <td>Alarm</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Klimazipfel</td>\n",
       "      <td>zipfel</td>\n",
       "      <td>[Zipfeln, Zipfel, Zipfels]</td>\n",
       "      <td>Zipfel</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Klimazirkus</td>\n",
       "      <td>zirkus</td>\n",
       "      <td>[Zirkusse, Zirkus, Zirkussen, Zirkusses]</td>\n",
       "      <td>Zirkus</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Klimazunft</td>\n",
       "      <td>zunft</td>\n",
       "      <td>[Zunft, Zünfte, Zünften]</td>\n",
       "      <td>Zunft</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Klimazwang</td>\n",
       "      <td>zwang</td>\n",
       "      <td>[Zwange, Zwängen, Zwangs, Zwanges, Zwang, Zwänge]</td>\n",
       "      <td>Zwang</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Klimaüberhitzung</td>\n",
       "      <td>überhitzung</td>\n",
       "      <td>[Überhitzungen, Überhitzung]</td>\n",
       "      <td>Überhitzung</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             original  second_part  \\\n",
       "0     Klimaabzockerei   abzockerei   \n",
       "1     Klimaaktivismus   aktivismus   \n",
       "2       Klimaaktivist     aktivist   \n",
       "3     Klimaaktivistin   aktivistin   \n",
       "4          Klimaalarm        alarm   \n",
       "..                ...          ...   \n",
       "243       Klimazipfel       zipfel   \n",
       "244       Klimazirkus       zirkus   \n",
       "245        Klimazunft        zunft   \n",
       "246        Klimazwang        zwang   \n",
       "247  Klimaüberhitzung  überhitzung   \n",
       "\n",
       "                                            noun_forms        lemma genus  \n",
       "0                                                 None         None  None  \n",
       "1                                                 None         None  None  \n",
       "2                               [Aktivisten, Aktivist]     Aktivist     m  \n",
       "3                          [Aktivistinnen, Aktivistin]   Aktivistin     f  \n",
       "4            [Alarms, Alarm, Alarmen, Alarme, Alarmes]        Alarm     m  \n",
       "..                                                 ...          ...   ...  \n",
       "243                         [Zipfeln, Zipfel, Zipfels]       Zipfel     m  \n",
       "244           [Zirkusse, Zirkus, Zirkussen, Zirkusses]       Zirkus     m  \n",
       "245                           [Zunft, Zünfte, Zünften]        Zunft     f  \n",
       "246  [Zwange, Zwängen, Zwangs, Zwanges, Zwang, Zwänge]        Zwang     m  \n",
       "247                       [Überhitzungen, Überhitzung]  Überhitzung     f  \n",
       "\n",
       "[248 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply functions to compound nouns \n",
    "compounds['noun_forms'] = compounds.second_part.apply(get_forms)\n",
    "compounds['lemma'] = compounds.second_part.apply(get_lemma)\n",
    "compounds['genus'] = compounds.second_part.apply(get_genus)\n",
    "\n",
    "compounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46031924-fb64-4e27-8ee0-ba04754e5aa2",
   "metadata": {},
   "source": [
    "Since the `german-nouns` library did not provide information for 15 of the compound words, we retrieve these words and manually retrieve the missing information from the Duden website (https://www.duden.de)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ccb9800-2b01-4191-a532-d5b053be9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 nouns could not be detected by german-nouns library\n",
    "# these are being declined manually using DUDEN website \n",
    "to_check = compounds[compounds[\"lemma\"].isna()].second_part.tolist()\n",
    "\n",
    "# save nouns that have to be checked to txt file \n",
    "file = open(\"../evaluation/to_check.txt\", \"w\")\n",
    "for element in to_check:\n",
    "    file.write(element + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947e9de-e949-4e95-b393-e77fb1d8b4ed",
   "metadata": {},
   "source": [
    "We re-load the retrieved word forms into Python and have a look at the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f4ec57c-8079-4f36-a168-16c54ab7d669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>second_part</th>\n",
       "      <th>noun_forms</th>\n",
       "      <th>genus</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>glaubenslehre</td>\n",
       "      <td>glaubenslehre, glaubenslehren</td>\n",
       "      <td>f</td>\n",
       "      <td>glaubenslehre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>verdummung</td>\n",
       "      <td>verdummung</td>\n",
       "      <td>f</td>\n",
       "      <td>verdummung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>notstandsregierung</td>\n",
       "      <td>notstandsregierung, notstandsregierungen</td>\n",
       "      <td>f</td>\n",
       "      <td>notstandsregierung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kasteiung</td>\n",
       "      <td>kasteiung, kasteiungen</td>\n",
       "      <td>f</td>\n",
       "      <td>kasteiung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bremser</td>\n",
       "      <td>bremser, bremsers, bremsern</td>\n",
       "      <td>m</td>\n",
       "      <td>bremser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>besoffenheit</td>\n",
       "      <td>besoffenheit</td>\n",
       "      <td>f</td>\n",
       "      <td>besoffenheit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>verblödung</td>\n",
       "      <td>verblödung</td>\n",
       "      <td>f</td>\n",
       "      <td>verblödung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alarmist</td>\n",
       "      <td>alarmist, alarmisten</td>\n",
       "      <td>m</td>\n",
       "      <td>alarmist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hysteriker</td>\n",
       "      <td>hysteriker, hysterikers, hysterikern</td>\n",
       "      <td>m</td>\n",
       "      <td>hysteriker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>donna</td>\n",
       "      <td>donna, donnas, donnen</td>\n",
       "      <td>f</td>\n",
       "      <td>donna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>aktivismus</td>\n",
       "      <td>aktivismus</td>\n",
       "      <td>m</td>\n",
       "      <td>aktivismus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gläubigkeit</td>\n",
       "      <td>gläubigkeit</td>\n",
       "      <td>f</td>\n",
       "      <td>gläubigkeit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abzockerei</td>\n",
       "      <td>abzockerei, abzockereien</td>\n",
       "      <td>f</td>\n",
       "      <td>abzockerei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bewegtheit</td>\n",
       "      <td>bewegtheit</td>\n",
       "      <td>f</td>\n",
       "      <td>bewegtheit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>orthodoxie</td>\n",
       "      <td>orthodoxie</td>\n",
       "      <td>f</td>\n",
       "      <td>orthodoxie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           second_part                                noun_forms genus  \\\n",
       "0        glaubenslehre             glaubenslehre, glaubenslehren     f   \n",
       "1           verdummung                                verdummung     f   \n",
       "2   notstandsregierung  notstandsregierung, notstandsregierungen     f   \n",
       "3            kasteiung                    kasteiung, kasteiungen     f   \n",
       "4              bremser               bremser, bremsers, bremsern     m   \n",
       "5         besoffenheit                              besoffenheit     f   \n",
       "6           verblödung                                verblödung     f   \n",
       "7             alarmist                      alarmist, alarmisten     m   \n",
       "8           hysteriker      hysteriker, hysterikers, hysterikern     m   \n",
       "9                donna                     donna, donnas, donnen     f   \n",
       "10          aktivismus                                aktivismus     m   \n",
       "11         gläubigkeit                               gläubigkeit     f   \n",
       "12          abzockerei                  abzockerei, abzockereien     f   \n",
       "13          bewegtheit                                bewegtheit     f   \n",
       "14          orthodoxie                                orthodoxie     f   \n",
       "\n",
       "                 lemma  \n",
       "0        glaubenslehre  \n",
       "1           verdummung  \n",
       "2   notstandsregierung  \n",
       "3            kasteiung  \n",
       "4              bremser  \n",
       "5         besoffenheit  \n",
       "6           verblödung  \n",
       "7             alarmist  \n",
       "8           hysteriker  \n",
       "9                donna  \n",
       "10          aktivismus  \n",
       "11         gläubigkeit  \n",
       "12          abzockerei  \n",
       "13          bewegtheit  \n",
       "14          orthodoxie  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open csv file with manually added noun forms, lemma and genus\n",
    "to_check_df = pd.read_csv(\"../evaluation/to_check_manual.csv\",sep=';', header=None, names=[\"second_part\", \"noun_forms\", \"genus\"])\n",
    "\n",
    "# lemma form is equal to second noun of composite\n",
    "to_check_df[\"lemma\"] = to_check_df[\"second_part\"]\n",
    "\n",
    "to_check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ef06e-f614-45df-ac45-3f1e71e06463",
   "metadata": {},
   "source": [
    "Now to, merge the manually retrieved information back into the complete data frame of the compound words, we convert the columns into a list format and use the `update` function of `pandas` to merge the information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07d433d3-3e6b-4b59-bdc3-04642605be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into correct format to be able to merge it to data frame \n",
    "noun_forms_df = to_check_df.noun_forms.values.tolist()\n",
    "   \n",
    "noun_forms_list = [element.split(\",\") for element in noun_forms_df]\n",
    "to_check_df[\"noun_forms\"] = noun_forms_list\n",
    "\n",
    "# put new information into original data frame containing all composites\n",
    "keys = [\"second_part\"]\n",
    "compounds = compounds.set_index(keys)\n",
    "compounds['noun_forms'].update(to_check_df.set_index(keys)['noun_forms'])\n",
    "compounds['lemma'].update(to_check_df.set_index(keys)['lemma'])\n",
    "compounds['genus'].update(to_check_df.set_index(keys)['genus'])\n",
    "compounds = compounds.reset_index()\n",
    "\n",
    "# change order of columns\n",
    "compounds = compounds[[\"original\", \"second_part\", \"noun_forms\", \"lemma\", \"genus\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17052977-7680-4fc6-9caf-f0f0b29ff3d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Normalization\n",
    "We now perform a few normalization steps to generate a final compound data frame which we can use as an input for upcoming text mining applications:\n",
    "- lowering of all strings in the data frame\n",
    "- re-adding of the \"klima\" prefix to the second constituents to generate complete compound forms (saved in column `compound_forms`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4461bb84-c01a-426e-82de-0a7ff7cfc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of noun forms for normalization \n",
    "noun_forms = compounds.noun_forms.tolist()\n",
    "\n",
    "# lower all strings in declension forms\n",
    "lower = [[string.lower().replace(\" \", \"\") for string in sublist] for sublist in noun_forms]\n",
    "\n",
    "# lower all lemmas \n",
    "compounds[\"lemma\"] = compounds[\"lemma\"].str.lower()\n",
    "compounds[\"original\"] = compounds[\"original\"].str.lower()\n",
    "\n",
    "# add \"klima\" compound part back to get complete compound word forms\n",
    "compound_forms = [[\"klima\" + word for word in element] for element in lower]\n",
    "\n",
    "# add complete compound word forms to data frame\n",
    "compounds[\"compound_forms\"] = compound_forms\n",
    "compounds[\"noun_forms\"] = lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7a01a-1f68-42e1-b2b3-eaf09030267e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Export Output\n",
    "Then we save this final compound data frame including all the information we retrieved in the steps above to the `compounds_info.csv` file which we can then use for the upcoming implementation methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9278c48-dba0-4b77-b366-e744892929fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final data frame to csv file\n",
    "compounds.to_csv(\"../files/compounds_info.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
